{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ee06c6-8714-4838-900d-093156cab4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pytorch geometry (グラフニューラルネットワークライブラリ) のインストール(only first time)\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
    "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98a707d-fd35-41b7-84e5-61b15bc64cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A module for molecules and stuff\n",
      "\n",
      " see Chem/index.html in the doc tree for documentation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ライブラリ確認\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Data as TorchGeometricData\n",
    "\n",
    "print(Chem.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbaef895-2412-4671-822b-9f5f1af22241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1214 molecules\n"
     ]
    }
   ],
   "source": [
    "#SDFファイルの読み込み\n",
    "import glob\n",
    "import re\n",
    "\n",
    "suppl  = Chem.SDMolSupplier(\"../../ForMolPredict/SDF_files/SOL/SOL_AllMOL.sdf\",removeHs=False) \n",
    "mol_list = [x for x in suppl]\n",
    "mol_num = len(mol_list)\n",
    "print(\"there are {} molecules\".format(mol_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556ec994-c873-469c-96b1-ff09500c458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detaの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_val, test = train_test_split(mol_list, random_state=0)\n",
    "train, val = train_test_split(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d321d3-1314-402a-9eab-67963070d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pandasのデータフレームからRDkitのmolオブジェクトXとラベルYのペアに変換\n",
    "\n",
    "Xwf={dataset_keyword:[] for dataset_keyword in [\"train\",\"valid\",\"test\"]}\n",
    "Ywf={dataset_keyword:[] for dataset_keyword in [\"train\",\"valid\",\"test\"]}\n",
    "#(A) lowを０それ以外を１とする\n",
    "for mol in train: \n",
    "    Xwf[\"train\"].append(mol)\n",
    "    if mol.GetProp('SOL_class')=='(A) low':\n",
    "        Ywf[\"train\"].append(0.0)\n",
    "    else:\n",
    "        Ywf[\"train\"].append(1.0)\n",
    "for mol in val: \n",
    "    Xwf[\"valid\"].append(mol)\n",
    "    if mol.GetProp('SOL_class')=='(A) low':\n",
    "        Ywf[\"valid\"].append(0.0)\n",
    "    else:\n",
    "        Ywf[\"valid\"].append(1.0)\n",
    "for mol in test:\n",
    "    Xwf[\"test\"].append(mol)\n",
    "    if mol.GetProp('SOL_class')=='(A) low':\n",
    "        Ywf[\"test\"].append(0.0)\n",
    "    else:\n",
    "        Ywf[\"test\"].append(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9ccf38-f6de-4277-ac2f-b49b22a8db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\n",
    "            \"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def get_atom_features(atom, en_list=None, explicit_H=False, use_sybyl=False, use_electronegativity=False,\n",
    "                  use_gasteiger=False, degree_dim=17):\n",
    "    if use_sybyl:\n",
    "        atom_type = ordkit._sybyl_atom_type(atom)\n",
    "        atom_list = ['C.ar', 'C.cat', 'C.1', 'C.2', 'C.3', 'N.ar', 'N.am', 'N.pl3', 'N.1', 'N.2', 'N.3', 'N.4', 'O.co2',\n",
    "                     'O.2', 'O.3', 'S.O', 'S.o2', 'S.2', 'S.3', 'F', 'Si', 'P', 'P3', 'Cl', 'Br', 'Mg', 'Na', 'Ca',\n",
    "                     'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
    "                     'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr', 'Pt', 'Hg', 'Pb', 'Unknown']\n",
    "    else:\n",
    "        atom_type = atom.GetSymbol()\n",
    "        atom_list = ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V',\n",
    "                     'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni',\n",
    "                     'Cd', 'In', 'Mn', 'Zr', 'Cr', 'Pt', 'Hg', 'Pb', 'Unknown']\n",
    "    results = one_of_k_encoding_unk(atom_type, atom_list) + \\\n",
    "        one_of_k_encoding(atom.GetDegree(), list(range(degree_dim))) + \\\n",
    "        one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6]) + \\\n",
    "        [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "        one_of_k_encoding_unk(atom.GetHybridization(),\n",
    "                              [Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                               Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
    "                               Chem.rdchem.HybridizationType.SP3D2]) + \\\n",
    "        [atom.GetIsAromatic()]\n",
    "\n",
    "    if use_electronegativity:\n",
    "        results = results + [en_list[atom.GetAtomicNum() - 1]]\n",
    "    if use_gasteiger:\n",
    "        gasteiger = atom.GetDoubleProp('_GasteigerCharge')\n",
    "        if np.isnan(gasteiger) or np.isinf(gasteiger):\n",
    "            gasteiger = 0  # because the mean is 0\n",
    "        results = results + [gasteiger]\n",
    "\n",
    "    # In case of explicit hydrogen(QM8, QM9), avoid calling `GetTotalNumHs`\n",
    "    if not explicit_H:\n",
    "        results = results + one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4])\n",
    "    return np.array(results, dtype=np.float32)\n",
    "\n",
    "def get_bond_features(bond):\n",
    "  results=one_of_k_encoding_unk(bond.GetBondType(),[Chem.rdchem.BondType.SINGLE,\n",
    "                         Chem.rdchem.BondType.DOUBLE,\n",
    "                         Chem.rdchem.BondType.TRIPLE,\n",
    "                         Chem.rdchem.BondType.AROMATIC])\n",
    "  return np.array(results, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e4910bf-aac3-4395-b35b-501e73817a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import Data as TorchGeometricData\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "def get_edge_features(mol):\n",
    "    edge_list= []\n",
    "    num_bond_features=0\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_features = get_bond_features(bond)\n",
    "        num_bond_features=len(bond_features)\n",
    "        edge_list += [([i, j],bond_features), ([j, i],bond_features)]\n",
    "    return edge_list, num_bond_features\n",
    "\n",
    "#modified mol2geodata\n",
    "#規格化関数\n",
    "def rescaling(features):\n",
    "    norm_features = []\n",
    "    max_value = max(features)\n",
    "    min_value = min(features)\n",
    "    for feature in features:\n",
    "        norm_feature = (feature - min_value)/(max_value - min_value)\n",
    "        norm_features.append(norm_feature)\n",
    "    \n",
    "    return norm_features\n",
    "\n",
    "def get_WF_results(mol):\n",
    "    mol_props = ['Volume', 'Energy', 'HOMO', 'LUMO', 'HLgap', 'Mcharge_ave', 'Mcharge_var', 'Lcharge_ave', 'Lcharge_var', 'dipole', 'Atom_num', 'Mass', 'Density']\n",
    "    atom_props = ['Mcharges', 'Lcharges', 'Mass', 'X_dem', 'Y_dem', 'Z_dem']\n",
    "    mol_datalist = []\n",
    "    WF_results = []\n",
    "    for mol_prop in mol_props:\n",
    "        mol_datalist.append(mol.GetDoubleProp(mol_prop))\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_data = []\n",
    "        for atom_prop in atom_props:\n",
    "            atom_data.append(atom.GetDoubleProp(atom_prop))\n",
    "            molatom_data = mol_datalist + atom_data\n",
    "        WF_results.append(molatom_data)\n",
    "    return np.array(WF_results, dtype=np.float32)\n",
    "\n",
    "def mol2geodataWF(mol,y):\n",
    "    smile = Chem.MolToSmiles(mol)\n",
    "    atom_features =[get_atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    WF_results = get_WF_results(mol)\n",
    "    atom_features = np.append(atom_features, WF_results, axis=1)\n",
    "    num_atom_features=len(atom_features[0])\n",
    "    atom_features = torch.FloatTensor(atom_features).view(-1, len(atom_features[0]))\n",
    "\n",
    "    edge_list,num_bond_features = get_edge_features(mol)\n",
    "    edge_list=sorted(edge_list)\n",
    "    \n",
    "    edge_indices=[e for e,v in edge_list]\n",
    "    edge_attributes=[v for e,v in edge_list]\n",
    "    edge_indices = torch.tensor(edge_indices)\n",
    "    edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "    edge_attributes = torch.FloatTensor(edge_attributes)\n",
    "    #print(num_atom_features,num_bond_features)\n",
    "    return TorchGeometricData(x=atom_features, edge_index=edge_indices, edge_attr=edge_attributes, num_atom_features=num_atom_features,num_bond_features=num_bond_features,smiles=smile, y=y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3dda169-92f5-4ec0-8d6c-0a066d0851f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuma/anaconda3/envs/chem/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_data_list = [mol2geodataWF(mol,y) for mol,y in zip(Xwf[\"train\"],Ywf[\"train\"])]\n",
    "train_loader = DataLoader(train_data_list, batch_size=128,shuffle=True)\n",
    "\n",
    "valid_data_list = [mol2geodataWF(mol,y) for mol,y in zip(Xwf[\"valid\"],Ywf[\"valid\"])]\n",
    "valid_loader = DataLoader(valid_data_list, batch_size=128,shuffle=True)\n",
    "\n",
    "test_data_list = [mol2geodataWF(mol,y) for mol,y in zip(Xwf[\"test\"],Ywf[\"test\"])]\n",
    "test_loader = DataLoader(test_data_list, batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27e07dd-240f-495a-bdce-33eb56a329a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_atom_features = 100\n",
      "num_bond_features = 4\n"
     ]
    }
   ],
   "source": [
    "num_atom_features = train_data_list[0].num_atom_features\n",
    "num_bond_features = train_data_list[0].num_bond_features\n",
    "\n",
    "print(\"num_atom_features =\",num_atom_features)\n",
    "print(\"num_bond_features =\",num_bond_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8d011e-2f10-4e49-9fbb-4835d22956b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークの構造の定義\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "\n",
    "dim = 64 # 中間層の次元\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin0 = torch.nn.Linear(num_atom_features, dim)\n",
    "\n",
    "        nn = Sequential(Linear(num_bond_features, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean')\n",
    "        self.gru = GRU(dim, dim)\n",
    "\n",
    "        self.set2set = Set2Set(dim, processing_steps=3)\n",
    "        self.lin1 = torch.nn.Linear(2 * dim, dim)\n",
    "        self.lin2 = torch.nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(3):\n",
    "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "\n",
    "        out = self.set2set(out, data.batch)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17058c0-77e8-4324-bd6c-4e07279dafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークの学習パラメータの定義\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.7, patience=5,min_lr=0.00001)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_step(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def test_step(loader):\n",
    "    model.eval()\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        loss = loss_function(model(data), data.y)\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "    return loss_all / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3508a871-7b17-45e3-ad16-d4d15a494d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, LR: 0.001000, Loss: 1.1022893, Validation loss: 0.7813503, Test loss: 0.7936083\n",
      "Epoch: 001, LR: 0.001000, Loss: 0.7509977, Validation loss: 0.6890599, Test loss: 0.6853815\n",
      "Epoch: 002, LR: 0.001000, Loss: 0.7763703, Validation loss: 0.6077581, Test loss: 0.6216355\n",
      "Epoch: 003, LR: 0.001000, Loss: 0.5851493, Validation loss: 0.5758690, Test loss: 0.5758689\n",
      "Epoch: 004, LR: 0.001000, Loss: 0.6102653, Validation loss: 0.5740793, Test loss: 0.5740344\n",
      "Epoch: 005, LR: 0.001000, Loss: 0.5767765, Validation loss: 0.5125458, Test loss: 0.5281407\n",
      "Epoch: 006, LR: 0.001000, Loss: 0.5219769, Validation loss: 0.5413732, Test loss: 0.5281407\n",
      "Epoch: 007, LR: 0.001000, Loss: 0.5152275, Validation loss: 0.5674338, Test loss: 0.5281407\n",
      "Epoch: 008, LR: 0.001000, Loss: 0.5497352, Validation loss: 0.5466520, Test loss: 0.5281407\n",
      "Epoch: 009, LR: 0.001000, Loss: 0.5349560, Validation loss: 0.4862863, Test loss: 0.4902830\n",
      "Epoch: 010, LR: 0.001000, Loss: 0.5306335, Validation loss: 0.5513079, Test loss: 0.4902830\n",
      "Epoch: 011, LR: 0.001000, Loss: 0.5965828, Validation loss: 0.5120872, Test loss: 0.4902830\n",
      "Epoch: 012, LR: 0.001000, Loss: 0.5537541, Validation loss: 0.5727759, Test loss: 0.4902830\n",
      "Epoch: 013, LR: 0.001000, Loss: 0.5333004, Validation loss: 0.4653822, Test loss: 0.4782499\n",
      "Epoch: 014, LR: 0.001000, Loss: 0.4856902, Validation loss: 0.4649394, Test loss: 0.4722159\n",
      "Epoch: 015, LR: 0.001000, Loss: 0.4880463, Validation loss: 0.4503746, Test loss: 0.4872122\n",
      "Epoch: 016, LR: 0.001000, Loss: 0.4875964, Validation loss: 0.5182745, Test loss: 0.4872122\n",
      "Epoch: 017, LR: 0.001000, Loss: 0.5035200, Validation loss: 0.4464649, Test loss: 0.4749307\n",
      "Epoch: 018, LR: 0.001000, Loss: 0.4746122, Validation loss: 0.4328343, Test loss: 0.4715272\n",
      "Epoch: 019, LR: 0.001000, Loss: 0.4886920, Validation loss: 0.5126211, Test loss: 0.4715272\n",
      "Epoch: 020, LR: 0.001000, Loss: 0.4769054, Validation loss: 0.4398091, Test loss: 0.4715272\n",
      "Epoch: 021, LR: 0.001000, Loss: 0.4317808, Validation loss: 0.4502278, Test loss: 0.4715272\n",
      "Epoch: 022, LR: 0.001000, Loss: 0.4354163, Validation loss: 0.4159976, Test loss: 0.4404687\n",
      "Epoch: 023, LR: 0.001000, Loss: 0.4179990, Validation loss: 0.4050319, Test loss: 0.4504351\n",
      "Epoch: 024, LR: 0.001000, Loss: 0.4156325, Validation loss: 0.4397740, Test loss: 0.4504351\n",
      "Epoch: 025, LR: 0.001000, Loss: 0.4157171, Validation loss: 0.4087756, Test loss: 0.4504351\n",
      "Epoch: 026, LR: 0.001000, Loss: 0.3990990, Validation loss: 0.3758971, Test loss: 0.4072757\n",
      "Epoch: 027, LR: 0.001000, Loss: 0.3781215, Validation loss: 0.3746893, Test loss: 0.4057205\n",
      "Epoch: 028, LR: 0.001000, Loss: 0.3772288, Validation loss: 0.3876987, Test loss: 0.4057205\n",
      "Epoch: 029, LR: 0.001000, Loss: 0.3804100, Validation loss: 0.3647759, Test loss: 0.3981682\n",
      "Epoch: 030, LR: 0.001000, Loss: 0.3781648, Validation loss: 0.3499898, Test loss: 0.3788369\n",
      "Epoch: 031, LR: 0.001000, Loss: 0.3698474, Validation loss: 0.3640135, Test loss: 0.3788369\n",
      "Epoch: 032, LR: 0.001000, Loss: 0.3606850, Validation loss: 0.3590283, Test loss: 0.3788369\n",
      "Epoch: 033, LR: 0.001000, Loss: 0.4165170, Validation loss: 0.4326548, Test loss: 0.3788369\n",
      "Epoch: 034, LR: 0.001000, Loss: 0.4698488, Validation loss: 0.4845140, Test loss: 0.3788369\n",
      "Epoch: 035, LR: 0.001000, Loss: 0.4295208, Validation loss: 0.3818158, Test loss: 0.3788369\n",
      "Epoch: 036, LR: 0.001000, Loss: 0.4035889, Validation loss: 0.3996918, Test loss: 0.3788369\n",
      "Epoch: 037, LR: 0.000700, Loss: 0.3779145, Validation loss: 0.3854420, Test loss: 0.3788369\n",
      "Epoch: 038, LR: 0.000700, Loss: 0.3570196, Validation loss: 0.3385121, Test loss: 0.3763388\n",
      "Epoch: 039, LR: 0.000700, Loss: 0.3629736, Validation loss: 0.3533426, Test loss: 0.3763388\n",
      "Epoch: 040, LR: 0.000700, Loss: 0.3536679, Validation loss: 0.3509159, Test loss: 0.3763388\n",
      "Epoch: 041, LR: 0.000700, Loss: 0.3273053, Validation loss: 0.3583085, Test loss: 0.3763388\n",
      "Epoch: 042, LR: 0.000700, Loss: 0.3381919, Validation loss: 0.3294661, Test loss: 0.3579082\n",
      "Epoch: 043, LR: 0.000700, Loss: 0.3364375, Validation loss: 0.3356038, Test loss: 0.3579082\n",
      "Epoch: 044, LR: 0.000700, Loss: 0.3292605, Validation loss: 0.3315363, Test loss: 0.3579082\n",
      "Epoch: 045, LR: 0.000700, Loss: 0.3149937, Validation loss: 0.3240954, Test loss: 0.3550546\n",
      "Epoch: 046, LR: 0.000700, Loss: 0.3201732, Validation loss: 0.3417162, Test loss: 0.3550546\n",
      "Epoch: 047, LR: 0.000700, Loss: 0.3191291, Validation loss: 0.3287192, Test loss: 0.3550546\n",
      "Epoch: 048, LR: 0.000700, Loss: 0.3202225, Validation loss: 0.3357893, Test loss: 0.3550546\n",
      "Epoch: 049, LR: 0.000700, Loss: 0.3279483, Validation loss: 0.3213335, Test loss: 0.3564931\n",
      "Epoch: 050, LR: 0.000700, Loss: 0.3278978, Validation loss: 0.3231611, Test loss: 0.3564931\n",
      "Epoch: 051, LR: 0.000700, Loss: 0.3217608, Validation loss: 0.3640405, Test loss: 0.3564931\n",
      "Epoch: 052, LR: 0.000700, Loss: 0.3480103, Validation loss: 0.3479157, Test loss: 0.3564931\n",
      "Epoch: 053, LR: 0.000700, Loss: 0.3216743, Validation loss: 0.3539492, Test loss: 0.3564931\n",
      "Epoch: 054, LR: 0.000700, Loss: 0.3056179, Validation loss: 0.3367120, Test loss: 0.3564931\n",
      "Epoch: 055, LR: 0.000700, Loss: 0.3132952, Validation loss: 0.3186079, Test loss: 0.3538866\n",
      "Epoch: 056, LR: 0.000700, Loss: 0.3084799, Validation loss: 0.3293298, Test loss: 0.3538866\n",
      "Epoch: 057, LR: 0.000700, Loss: 0.3157354, Validation loss: 0.3279295, Test loss: 0.3538866\n",
      "Epoch: 058, LR: 0.000700, Loss: 0.3019371, Validation loss: 0.3150683, Test loss: 0.3547535\n",
      "Epoch: 059, LR: 0.000700, Loss: 0.2969490, Validation loss: 0.3247770, Test loss: 0.3547535\n",
      "Epoch: 060, LR: 0.000700, Loss: 0.3093222, Validation loss: 0.3157025, Test loss: 0.3547535\n",
      "Epoch: 061, LR: 0.000700, Loss: 0.3187556, Validation loss: 0.3159379, Test loss: 0.3547535\n",
      "Epoch: 062, LR: 0.000700, Loss: 0.3126511, Validation loss: 0.3370150, Test loss: 0.3547535\n",
      "Epoch: 063, LR: 0.000700, Loss: 0.3307188, Validation loss: 0.3317004, Test loss: 0.3547535\n",
      "Epoch: 064, LR: 0.000700, Loss: 0.3203799, Validation loss: 0.3592719, Test loss: 0.3547535\n",
      "Epoch: 065, LR: 0.000490, Loss: 0.3159533, Validation loss: 0.3353305, Test loss: 0.3547535\n",
      "Epoch: 066, LR: 0.000490, Loss: 0.3037580, Validation loss: 0.3439440, Test loss: 0.3547535\n",
      "Epoch: 067, LR: 0.000490, Loss: 0.3035647, Validation loss: 0.3328323, Test loss: 0.3547535\n",
      "Epoch: 068, LR: 0.000490, Loss: 0.2904192, Validation loss: 0.3342495, Test loss: 0.3547535\n",
      "Epoch: 069, LR: 0.000490, Loss: 0.2993240, Validation loss: 0.3191056, Test loss: 0.3547535\n",
      "Epoch: 070, LR: 0.000490, Loss: 0.2881199, Validation loss: 0.3223298, Test loss: 0.3547535\n",
      "Epoch: 071, LR: 0.000343, Loss: 0.2906183, Validation loss: 0.3150512, Test loss: 0.3551732\n",
      "Epoch: 072, LR: 0.000343, Loss: 0.2865221, Validation loss: 0.3403949, Test loss: 0.3551732\n",
      "Epoch: 073, LR: 0.000343, Loss: 0.2937562, Validation loss: 0.3198384, Test loss: 0.3551732\n",
      "Epoch: 074, LR: 0.000343, Loss: 0.3013451, Validation loss: 0.3133860, Test loss: 0.3412171\n",
      "Epoch: 075, LR: 0.000343, Loss: 0.3039692, Validation loss: 0.3086854, Test loss: 0.3511409\n",
      "Epoch: 076, LR: 0.000343, Loss: 0.3157706, Validation loss: 0.3026500, Test loss: 0.3382869\n",
      "Epoch: 077, LR: 0.000343, Loss: 0.3121213, Validation loss: 0.3233996, Test loss: 0.3382869\n",
      "Epoch: 078, LR: 0.000343, Loss: 0.3139203, Validation loss: 0.3152246, Test loss: 0.3382869\n",
      "Epoch: 079, LR: 0.000343, Loss: 0.2950204, Validation loss: 0.3633991, Test loss: 0.3382869\n",
      "Epoch: 080, LR: 0.000343, Loss: 0.3022848, Validation loss: 0.3275949, Test loss: 0.3382869\n",
      "Epoch: 081, LR: 0.000343, Loss: 0.2958733, Validation loss: 0.3041683, Test loss: 0.3382869\n",
      "Epoch: 082, LR: 0.000343, Loss: 0.2855295, Validation loss: 0.3222078, Test loss: 0.3382869\n",
      "Epoch: 083, LR: 0.000240, Loss: 0.2783342, Validation loss: 0.3174345, Test loss: 0.3382869\n",
      "Epoch: 084, LR: 0.000240, Loss: 0.2764900, Validation loss: 0.3185702, Test loss: 0.3382869\n",
      "Epoch: 085, LR: 0.000240, Loss: 0.2785434, Validation loss: 0.3191316, Test loss: 0.3382869\n",
      "Epoch: 086, LR: 0.000240, Loss: 0.2802823, Validation loss: 0.3146253, Test loss: 0.3382869\n",
      "Epoch: 087, LR: 0.000240, Loss: 0.2781254, Validation loss: 0.3234781, Test loss: 0.3382869\n",
      "Epoch: 088, LR: 0.000240, Loss: 0.2802150, Validation loss: 0.3205344, Test loss: 0.3382869\n",
      "Epoch: 089, LR: 0.000168, Loss: 0.2817008, Validation loss: 0.3094477, Test loss: 0.3382869\n",
      "Epoch: 090, LR: 0.000168, Loss: 0.2719039, Validation loss: 0.3025544, Test loss: 0.3430774\n",
      "Epoch: 091, LR: 0.000168, Loss: 0.2767632, Validation loss: 0.3057239, Test loss: 0.3430774\n",
      "Epoch: 092, LR: 0.000168, Loss: 0.2837609, Validation loss: 0.3303587, Test loss: 0.3430774\n",
      "Epoch: 093, LR: 0.000168, Loss: 0.2744859, Validation loss: 0.3051655, Test loss: 0.3430774\n",
      "Epoch: 094, LR: 0.000168, Loss: 0.2757913, Validation loss: 0.3051868, Test loss: 0.3430774\n",
      "Epoch: 095, LR: 0.000168, Loss: 0.2724852, Validation loss: 0.3128392, Test loss: 0.3430774\n",
      "Epoch: 096, LR: 0.000168, Loss: 0.2751624, Validation loss: 0.3094722, Test loss: 0.3430774\n",
      "Epoch: 097, LR: 0.000118, Loss: 0.2701912, Validation loss: 0.3062750, Test loss: 0.3430774\n",
      "Epoch: 098, LR: 0.000118, Loss: 0.2725306, Validation loss: 0.3026144, Test loss: 0.3430774\n",
      "Epoch: 099, LR: 0.000118, Loss: 0.2696800, Validation loss: 0.3070062, Test loss: 0.3430774\n",
      "Epoch: 100, LR: 0.000118, Loss: 0.2700669, Validation loss: 0.3096811, Test loss: 0.3430774\n",
      "Epoch: 101, LR: 0.000118, Loss: 0.2716623, Validation loss: 0.3120107, Test loss: 0.3430774\n",
      "Epoch: 102, LR: 0.000118, Loss: 0.2704542, Validation loss: 0.3087305, Test loss: 0.3430774\n",
      "Epoch: 103, LR: 0.000082, Loss: 0.2696460, Validation loss: 0.3132561, Test loss: 0.3430774\n",
      "Epoch: 104, LR: 0.000082, Loss: 0.2692551, Validation loss: 0.3133789, Test loss: 0.3430774\n",
      "Epoch: 105, LR: 0.000082, Loss: 0.2691385, Validation loss: 0.3101038, Test loss: 0.3430774\n",
      "Epoch: 106, LR: 0.000082, Loss: 0.2686936, Validation loss: 0.3047580, Test loss: 0.3430774\n",
      "Epoch: 107, LR: 0.000082, Loss: 0.2682578, Validation loss: 0.3047236, Test loss: 0.3430774\n",
      "Epoch: 108, LR: 0.000082, Loss: 0.2682005, Validation loss: 0.3037546, Test loss: 0.3430774\n",
      "Epoch: 109, LR: 0.000058, Loss: 0.2675677, Validation loss: 0.3037738, Test loss: 0.3430774\n",
      "Epoch: 110, LR: 0.000058, Loss: 0.2672077, Validation loss: 0.3048255, Test loss: 0.3430774\n",
      "Epoch: 111, LR: 0.000058, Loss: 0.2683663, Validation loss: 0.3088440, Test loss: 0.3430774\n",
      "Epoch: 112, LR: 0.000058, Loss: 0.2675101, Validation loss: 0.3062618, Test loss: 0.3430774\n",
      "Epoch: 113, LR: 0.000058, Loss: 0.2680358, Validation loss: 0.3050621, Test loss: 0.3430774\n",
      "Epoch: 114, LR: 0.000058, Loss: 0.2673548, Validation loss: 0.3069571, Test loss: 0.3430774\n",
      "Epoch: 115, LR: 0.000040, Loss: 0.2669780, Validation loss: 0.3063557, Test loss: 0.3430774\n",
      "Epoch: 116, LR: 0.000040, Loss: 0.2664638, Validation loss: 0.3091599, Test loss: 0.3430774\n",
      "Epoch: 117, LR: 0.000040, Loss: 0.2667936, Validation loss: 0.3082406, Test loss: 0.3430774\n",
      "Epoch: 118, LR: 0.000040, Loss: 0.2664978, Validation loss: 0.3044713, Test loss: 0.3430774\n",
      "Epoch: 119, LR: 0.000040, Loss: 0.2667568, Validation loss: 0.3031685, Test loss: 0.3430774\n",
      "Epoch: 120, LR: 0.000040, Loss: 0.2670614, Validation loss: 0.3038983, Test loss: 0.3430774\n",
      "Epoch: 121, LR: 0.000028, Loss: 0.2660326, Validation loss: 0.3067031, Test loss: 0.3430774\n",
      "Epoch: 122, LR: 0.000028, Loss: 0.2661030, Validation loss: 0.3081476, Test loss: 0.3430774\n",
      "Epoch: 123, LR: 0.000028, Loss: 0.2665847, Validation loss: 0.3088308, Test loss: 0.3430774\n",
      "Epoch: 124, LR: 0.000028, Loss: 0.2660490, Validation loss: 0.3069697, Test loss: 0.3430774\n",
      "Epoch: 125, LR: 0.000028, Loss: 0.2661320, Validation loss: 0.3058078, Test loss: 0.3430774\n",
      "Epoch: 126, LR: 0.000028, Loss: 0.2661548, Validation loss: 0.3058918, Test loss: 0.3430774\n",
      "Epoch: 127, LR: 0.000020, Loss: 0.2659233, Validation loss: 0.3060609, Test loss: 0.3430774\n",
      "Epoch: 128, LR: 0.000020, Loss: 0.2657497, Validation loss: 0.3059674, Test loss: 0.3430774\n",
      "Epoch: 129, LR: 0.000020, Loss: 0.2657343, Validation loss: 0.3061775, Test loss: 0.3430774\n",
      "Epoch: 130, LR: 0.000020, Loss: 0.2656359, Validation loss: 0.3055702, Test loss: 0.3430774\n",
      "Epoch: 131, LR: 0.000020, Loss: 0.2658054, Validation loss: 0.3048231, Test loss: 0.3430774\n",
      "Epoch: 132, LR: 0.000020, Loss: 0.2657088, Validation loss: 0.3052955, Test loss: 0.3430774\n",
      "Epoch: 133, LR: 0.000014, Loss: 0.2654007, Validation loss: 0.3064600, Test loss: 0.3430774\n",
      "Epoch: 134, LR: 0.000014, Loss: 0.2655058, Validation loss: 0.3065407, Test loss: 0.3430774\n",
      "Epoch: 135, LR: 0.000014, Loss: 0.2653850, Validation loss: 0.3053500, Test loss: 0.3430774\n",
      "Epoch: 136, LR: 0.000014, Loss: 0.2655606, Validation loss: 0.3041760, Test loss: 0.3430774\n",
      "Epoch: 137, LR: 0.000014, Loss: 0.2653821, Validation loss: 0.3043425, Test loss: 0.3430774\n",
      "Epoch: 138, LR: 0.000014, Loss: 0.2654751, Validation loss: 0.3043806, Test loss: 0.3430774\n",
      "Epoch: 139, LR: 0.000010, Loss: 0.2655248, Validation loss: 0.3048354, Test loss: 0.3430774\n",
      "Epoch: 140, LR: 0.000010, Loss: 0.2653794, Validation loss: 0.3041636, Test loss: 0.3430774\n",
      "Epoch: 141, LR: 0.000010, Loss: 0.2653657, Validation loss: 0.3038349, Test loss: 0.3430774\n",
      "Epoch: 142, LR: 0.000010, Loss: 0.2654139, Validation loss: 0.3035292, Test loss: 0.3430774\n",
      "Epoch: 143, LR: 0.000010, Loss: 0.2653212, Validation loss: 0.3037802, Test loss: 0.3430774\n",
      "Epoch: 144, LR: 0.000010, Loss: 0.2652999, Validation loss: 0.3045578, Test loss: 0.3430774\n",
      "Epoch: 145, LR: 0.000010, Loss: 0.2652095, Validation loss: 0.3052632, Test loss: 0.3430774\n",
      "Epoch: 146, LR: 0.000010, Loss: 0.2651844, Validation loss: 0.3057883, Test loss: 0.3430774\n",
      "Epoch: 147, LR: 0.000010, Loss: 0.2651977, Validation loss: 0.3058470, Test loss: 0.3430774\n",
      "Epoch: 148, LR: 0.000010, Loss: 0.2652154, Validation loss: 0.3048500, Test loss: 0.3430774\n",
      "Epoch: 149, LR: 0.000010, Loss: 0.2651127, Validation loss: 0.3049462, Test loss: 0.3430774\n",
      "Epoch: 150, LR: 0.000010, Loss: 0.2651736, Validation loss: 0.3051907, Test loss: 0.3430774\n",
      "Epoch: 151, LR: 0.000010, Loss: 0.2650929, Validation loss: 0.3051945, Test loss: 0.3430774\n",
      "Epoch: 152, LR: 0.000010, Loss: 0.2650752, Validation loss: 0.3057942, Test loss: 0.3430774\n",
      "Epoch: 153, LR: 0.000010, Loss: 0.2650371, Validation loss: 0.3057987, Test loss: 0.3430774\n",
      "Epoch: 154, LR: 0.000010, Loss: 0.2650192, Validation loss: 0.3050964, Test loss: 0.3430774\n",
      "Epoch: 155, LR: 0.000010, Loss: 0.2650294, Validation loss: 0.3047560, Test loss: 0.3430774\n",
      "Epoch: 156, LR: 0.000010, Loss: 0.2650241, Validation loss: 0.3042805, Test loss: 0.3430774\n",
      "Epoch: 157, LR: 0.000010, Loss: 0.2651238, Validation loss: 0.3036898, Test loss: 0.3430774\n",
      "Epoch: 158, LR: 0.000010, Loss: 0.2650731, Validation loss: 0.3036155, Test loss: 0.3430774\n",
      "Epoch: 159, LR: 0.000010, Loss: 0.2649975, Validation loss: 0.3040957, Test loss: 0.3430774\n",
      "Epoch: 160, LR: 0.000010, Loss: 0.2649814, Validation loss: 0.3045808, Test loss: 0.3430774\n",
      "Epoch: 161, LR: 0.000010, Loss: 0.2648665, Validation loss: 0.3046505, Test loss: 0.3430774\n",
      "Epoch: 162, LR: 0.000010, Loss: 0.2648524, Validation loss: 0.3045637, Test loss: 0.3430774\n",
      "Epoch: 163, LR: 0.000010, Loss: 0.2649050, Validation loss: 0.3045060, Test loss: 0.3430774\n",
      "Epoch: 164, LR: 0.000010, Loss: 0.2648914, Validation loss: 0.3048037, Test loss: 0.3430774\n",
      "Epoch: 165, LR: 0.000010, Loss: 0.2652397, Validation loss: 0.3054456, Test loss: 0.3430774\n",
      "Epoch: 166, LR: 0.000010, Loss: 0.2650829, Validation loss: 0.3046892, Test loss: 0.3430774\n",
      "Epoch: 167, LR: 0.000010, Loss: 0.2649127, Validation loss: 0.3044707, Test loss: 0.3430774\n",
      "Epoch: 168, LR: 0.000010, Loss: 0.2647948, Validation loss: 0.3047272, Test loss: 0.3430774\n",
      "Epoch: 169, LR: 0.000010, Loss: 0.2647652, Validation loss: 0.3054370, Test loss: 0.3430774\n",
      "Epoch: 170, LR: 0.000010, Loss: 0.2647970, Validation loss: 0.3067233, Test loss: 0.3430774\n",
      "Epoch: 171, LR: 0.000010, Loss: 0.2648303, Validation loss: 0.3075734, Test loss: 0.3430774\n",
      "Epoch: 172, LR: 0.000010, Loss: 0.2650716, Validation loss: 0.3075425, Test loss: 0.3430774\n",
      "Epoch: 173, LR: 0.000010, Loss: 0.2648916, Validation loss: 0.3069674, Test loss: 0.3430774\n",
      "Epoch: 174, LR: 0.000010, Loss: 0.2648852, Validation loss: 0.3064851, Test loss: 0.3430774\n",
      "Epoch: 175, LR: 0.000010, Loss: 0.2647483, Validation loss: 0.3061078, Test loss: 0.3430774\n",
      "Epoch: 176, LR: 0.000010, Loss: 0.2646999, Validation loss: 0.3063928, Test loss: 0.3430774\n",
      "Epoch: 177, LR: 0.000010, Loss: 0.2647037, Validation loss: 0.3061413, Test loss: 0.3430774\n",
      "Epoch: 178, LR: 0.000010, Loss: 0.2648043, Validation loss: 0.3058159, Test loss: 0.3430774\n",
      "Epoch: 179, LR: 0.000010, Loss: 0.2647680, Validation loss: 0.3057467, Test loss: 0.3430774\n",
      "Epoch: 180, LR: 0.000010, Loss: 0.2647270, Validation loss: 0.3058582, Test loss: 0.3430774\n",
      "Epoch: 181, LR: 0.000010, Loss: 0.2646206, Validation loss: 0.3056031, Test loss: 0.3430774\n",
      "Epoch: 182, LR: 0.000010, Loss: 0.2645297, Validation loss: 0.3049453, Test loss: 0.3430774\n",
      "Epoch: 183, LR: 0.000010, Loss: 0.2646042, Validation loss: 0.3041892, Test loss: 0.3430774\n",
      "Epoch: 184, LR: 0.000010, Loss: 0.2645920, Validation loss: 0.3041769, Test loss: 0.3430774\n",
      "Epoch: 185, LR: 0.000010, Loss: 0.2645620, Validation loss: 0.3041274, Test loss: 0.3430774\n",
      "Epoch: 186, LR: 0.000010, Loss: 0.2645098, Validation loss: 0.3044351, Test loss: 0.3430774\n",
      "Epoch: 187, LR: 0.000010, Loss: 0.2644311, Validation loss: 0.3048283, Test loss: 0.3430774\n",
      "Epoch: 188, LR: 0.000010, Loss: 0.2643759, Validation loss: 0.3046521, Test loss: 0.3430774\n",
      "Epoch: 189, LR: 0.000010, Loss: 0.2643343, Validation loss: 0.3044620, Test loss: 0.3430774\n",
      "Epoch: 190, LR: 0.000010, Loss: 0.2643566, Validation loss: 0.3042132, Test loss: 0.3430774\n",
      "Epoch: 191, LR: 0.000010, Loss: 0.2645731, Validation loss: 0.3040435, Test loss: 0.3430774\n",
      "Epoch: 192, LR: 0.000010, Loss: 0.2644878, Validation loss: 0.3042894, Test loss: 0.3430774\n",
      "Epoch: 193, LR: 0.000010, Loss: 0.2646412, Validation loss: 0.3043197, Test loss: 0.3430774\n",
      "Epoch: 194, LR: 0.000010, Loss: 0.2643866, Validation loss: 0.3043077, Test loss: 0.3430774\n",
      "Epoch: 195, LR: 0.000010, Loss: 0.2643713, Validation loss: 0.3040810, Test loss: 0.3430774\n",
      "Epoch: 196, LR: 0.000010, Loss: 0.2643674, Validation loss: 0.3033549, Test loss: 0.3430774\n",
      "Epoch: 197, LR: 0.000010, Loss: 0.2642897, Validation loss: 0.3036678, Test loss: 0.3430774\n",
      "Epoch: 198, LR: 0.000010, Loss: 0.2642007, Validation loss: 0.3033203, Test loss: 0.3430774\n",
      "Epoch: 199, LR: 0.000010, Loss: 0.2642181, Validation loss: 0.3030943, Test loss: 0.3430774\n"
     ]
    }
   ],
   "source": [
    "# 学習開始\n",
    "Epoch_list = []\n",
    "Loss_list = []\n",
    "Val_list = []\n",
    "Test_list =[]\n",
    "best_valid_loss = None\n",
    "for epoch in range(200):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    loss = train_step(epoch)\n",
    "    valid_loss = test_step(valid_loader)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if best_valid_loss is None or valid_loss <= best_valid_loss:\n",
    "        test_loss = test_step(test_loader)\n",
    "        best_valid_loss = valid_loss\n",
    "    Epoch_list.append(epoch)\n",
    "    Loss_list.append(loss)\n",
    "    Val_list.append(valid_loss)\n",
    "    Test_list.append(test_loss)\n",
    "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation loss: {:.7f}, '\n",
    "          'Test loss: {:.7f}'.format(epoch, lr, loss, valid_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8497d7a1-1974-4ae1-b1e4-9f85a2066223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#グラフ化\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(Epoch_list, Loss_list, label = 'Loss')\n",
    "plt.plot(Epoch_list, Val_list, label = 'Validation loss')\n",
    "plt.plot(Epoch_list, Test_list, label = 'Test loss')\n",
    "\n",
    "# 凡例を表示\n",
    "plt.legend(loc=5)\n",
    "\n",
    "# 軸ラベル\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
